{"cells":[{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive/')\n","!pip install thop\n","!pip install ptflops\n"],"metadata":{"id":"PRkP6rF6RZpZ"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":9,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2515,"status":"ok","timestamp":1657645404056,"user":{"displayName":"Marco Tommasini","userId":"11815747515139464141"},"user_tz":-120},"id":"JtPn153aQWbT","outputId":"d137a847-3282-4e02-b35b-2642e5fdf4c1"},"outputs":[{"output_type":"stream","name":"stdout","text":["say your name marco\n","/content/drive/MyDrive/Fourth Year/Machine learning and Deep learning Course/task_3\n"]}],"source":["\n","\n","#change the directory manually if you are not marco or allan\n","who_is_accesing = input(\"say your name \")\n","if who_is_accesing == \"marco\":\n","  %cd \"/content/drive/MyDrive/Fourth Year/Machine learning and Deep learning Course/task_3\"\n","  directory  = \"/content/drive/MyDrive/Fourth Year/Machine learning and Deep learning Course/task_3\"\n","elif who_is_accesing == \"allan\":\n","  %cd \"/content/drive/MyDrive/Summer 2022/task_3\"\n","  directory = \"/content/drive/MyDrive/Summer 2022/task_3\"\n","elif who_is_accesing == \"mldl\":\n","  %cd \"/content/drive/MyDrive/task_3\"\n","  directory = \"/content/drive/MyDrive/task_3\"\n"]},{"cell_type":"code","execution_count":10,"metadata":{"id":"j0USxckqQI8N","executionInfo":{"status":"ok","timestamp":1657645404057,"user_tz":-120,"elapsed":8,"user":{"displayName":"Marco Tommasini","userId":"11815747515139464141"}}},"outputs":[],"source":["\n","import torch\n","import torch.nn.functional as F\n","from tqdm import tqdm\n","import numpy as np\n","from utils import poly_lr_scheduler\n","from utils import reverse_one_hot, compute_global_accuracy, fast_hist, per_class_iu\n","from torch.autograd import Variable\n","\n","import torch.cuda.amp as amp\n","import argparse\n","import argparse\n","from torch.utils.data import Dataset\n","from torch.utils.data import DataLoader\n","import os\n","import time\n","#Models\n","from model.build_BiSeNet import BiSeNet\n","from model.discriminator import Discriminator\n","from model.discriminator import DiscriminatorSEP\n","\n","#losses\n","from loss import CrossEntropyLoss\n","from torch.nn import BCEWithLogitsLoss\n","from loss import DiceLoss\n","from loss import find_frequency_class\n","from loss import get_weights_classes_inverse\n","from loss import calculate_weigths_labels\n","from loss import FocalLoss\n","\n","#datasets\n","from dataset.cityscapes_dataset import CityScapeDataSet\n","from dataset.gta5_dataset import GTA5DataSet\n","from dataset.cityscapes_dataset_val import CityScapeDataSet_val\n","\n"]},{"cell_type":"code","execution_count":11,"metadata":{"id":"Simx9jqdI8ne","executionInfo":{"status":"ok","timestamp":1657645404057,"user_tz":-120,"elapsed":7,"user":{"displayName":"Marco Tommasini","userId":"11815747515139464141"}}},"outputs":[],"source":["def validation_segmentation(args, modelSEG, dataloader, name_instance):\n","  print('start validation')\n","  with torch.no_grad(): \n","    modelSEG.eval()\n","    precision_record = []\n","    hist = np.zeros((args.num_classes, args.num_classes))\n","\n","    for i, (image, label) in enumerate(dataloader):\n","      label = label.type(torch.LongTensor)\n","      label = label.long().cuda()\n","      image = image.cuda()\n","\n","      # get RGB predict image\n","      predict = modelSEG(image).squeeze()\n","      \n","      predict = reverse_one_hot(predict)\n","     \n","      predict = predict.cpu().numpy()\n","      \n","\n","      # get RGB label image\n","      label = label.squeeze()\n","      label = np.array(label.cpu())\n","\n","      # compute per pixel accuracy\n","      precision = compute_global_accuracy(predict, label)\n","      hist += fast_hist(label.flatten(), predict.flatten(), args.num_classes)\n","      \n","      precision_record.append(precision)\n","\n","    precision = np.mean(precision_record)\n","    miou_list = per_class_iu(hist)\n","    miou = np.mean(miou_list)\n","    print('precision per pixel for test: %.3f' % precision)\n","    print('mIoU for validation: %.3f' % miou)\n","    print(f'mIoU per class: {miou_list}')\n","\n","    name_file = \"_\".join(tuple(name_instance.split(\"_\")[0:5]))\n","\n","    #Save the results in a file inside the validation folder\n","    with open(args.val_results_directory + \"/\" + name_file + \".txt\", \"w\") as pipe:\n","      pipe.write(\"Precision per pixel: \" + str(precision) + \"\\n\")\n","      pipe.write(\"Average mIoU: \" + str(miou) + \"\\n\")\n","      for index, x in enumerate(miou_list):\n","        pipe.write(\"Class \" + str(index) + \": \" + str(x) + \"\\n\")\n","\n","\n","  return precision, miou"]},{"cell_type":"code","execution_count":12,"metadata":{"id":"VmKYo3m3FjfT","executionInfo":{"status":"ok","timestamp":1657645404281,"user_tz":-120,"elapsed":231,"user":{"displayName":"Marco Tommasini","userId":"11815747515139464141"}}},"outputs":[],"source":["def train_model(args, modelSEG, modelADV, optimizerSEG, optimizerADV, dataloader_target, dataloader_source, model_seg_dictionary = None, model_adv_dictionary = None):\n","  \n","  #initialize the dictionaries for the checkpoints\n","  if model_seg_dictionary != None and model_adv_dictionary != None:\n","    print(\"Using checkpoints\")\n","    modelSEG.load_state_dict(model_seg_dictionary['model_state_dict'])\n","    modelADV.load_state_dict(model_adv_dictionary['model_state_dict'])\n","\n","    optimizerSEG.load_state_dict(model_seg_dictionary['optimizer_state_dict'])\n","    optimizerADV.load_state_dict(model_adv_dictionary['optimizer_state_dict'])\n","\n","    initial_epoch = model_seg_dictionary[\"epoch\"]\n","    checkpoint = True\n","\n","  else:\n","    initial_epoch = 0\n","\n","  #initializing scaler object\n","  scaler = amp.GradScaler()\n","\n","  #set the model to train mode\n","  modelSEG.train()\n","  modelADV.train()\n","\n","\n","  #Setting the losses functions\n","  if args.weights_loss == \"False\":\n","    print(\"Not using loss weights\")\n","    weights_loss = torch.ones(args.num_classes).cuda()\n","    weights_loss = weights_loss.float()\n","  else:\n","    print(\"Using loss weights\")\n","    #In here it tries to read the weights from the stored folder,\n","    # if it fails it will calculate again the loss weights\n","    try:\n","      weights_loss = torch.tensor(np.load(os.path.join(args.weights_loss_dir, 'classes_weights.npy')))\n","      weights_loss = weights_loss.cuda().float()\n","      print(weights_loss)\n","    except:\n","      weights_loss = calculate_weigths_labels(args.weights_loss_dir, dataloader_source, args.num_classes)\n","      weights_loss = weights_loss.cuda()\n","      print(weights_loss)\n","  \n","  if args.loss_type == \"CrossEntropy\":\n","    loss_seg_source = torch.nn.CrossEntropyLoss(weight = weights_loss, ignore_index=255) #loss to train the segmentation network with the source dataset\n","    loss_adv_target_source = torch.nn.BCEWithLogitsLoss() #loss to train the segmenation network with the target dataset via the adversarial network\n","  else:\n","    loss_seg_source = FocalLoss(weight = weights_loss, ignore_index=255) #loss to train the segmentation network with the source dataset\n","    loss_adv_target_source = torch.nn.BCEWithLogitsLoss() #loss to train the segmenation network with the target dataset via the adversarial network\n","\n","  loss_D = torch.nn.BCEWithLogitsLoss() #loss to train only the adversarial network\n","\n","  # labels for adversarial training\n","  source_label = 0\n","  target_label = 1\n","\n","  #Defining the optmizers\n","  optmizer_segmentation = optimizerSEG\n","  optmizer_adversarial = optimizerADV\n","\n","  epoch = initial_epoch\n","  \n","  while epoch < args.num_epochs:\n","    print(\"Epoch = \",epoch)\n","\n","    pres = 0\n","    prev = 0\n","    #Defining the iterator object for the dataloaders\n","    dataloader_source_iter = enumerate(dataloader_source)\n","    dataloader_target_iter = enumerate(dataloader_target)  \n","\n","    #Update learning rate\n","    lr_seg = poly_lr_scheduler(optimizerSEG, args.learning_rate, iter=epoch, max_iter=args.num_epochs)\n","    lr_adv = poly_lr_scheduler(optimizerADV, args.learning_rate_adversarial, iter=epoch, max_iter=args.num_epochs)\n","    tq = tqdm(total=len(dataloader_source) * args.batch_size)\n","    tq.set_description('epoch %d, lr %f' % (epoch, args.learning_rate))\n","\n","\n","    for i, (data, label) in dataloader_source_iter:\n","      optimizerSEG.zero_grad()\n","      optimizerADV.zero_grad()\n","      \n","      for param in modelADV.parameters():\n","        param.requires_grad = False\n","    \n","      try:\n","        _, batch_target = dataloader_target_iter.__next__()\n","      except:\n","        dataloader_target_iter = enumerate(dataloader_target)\n","        _, batch_target = dataloader_target_iter.__next__()\n","\n","    \n","      images_source = data.cuda()\n","      labels_source = label.long().cuda()\n","      images_target = batch_target\n","      images_target = images_target.cuda()\n","\n","\n","      #Computing the losses from the output of the seg net\n","      with amp.autocast(): \n","        output_source_seg_seg, output_sup1_source_seg, output_sup2_source_seg = modelSEG(images_source)\n","        \n","        loss1_source_seg = loss_seg_source(output_source_seg_seg, labels_source)\n","        loss2_source_seg = loss_seg_source(output_sup1_source_seg, labels_source)\n","        loss3_source_seg = loss_seg_source(output_sup2_source_seg, labels_source)\n","        loss_source_seg = loss1_source_seg + loss2_source_seg + loss3_source_seg\n","\n","        output_target_seg_seg, _, _ = modelSEG(images_target)\n","        output_target_adv_seg = modelADV(F.softmax(output_target_seg_seg))\n","        loss_buffer_target_seg = loss_adv_target_source(output_target_adv_seg, Variable(torch.FloatTensor(output_target_adv_seg.data.size()).fill_(source_label)).cuda())\n","        loss_target_seg = args.lambda_adv_target * loss_buffer_target_seg\n","        \n","        loss_tot = loss_source_seg + loss_target_seg\n","        scaler.scale(loss_tot).backward()\n","\n","      \n","      ###Train the adversarial net\n","      #Start to accumulate grads in D while training the adversarial network\n","      for param in modelADV.parameters():\n","        param.requires_grad = True\n","\n","      ##Train adversarial network with source dataset\n","      #detatching the output_source from the segnet\n","      output_source_seg_seg = output_source_seg_seg.detach()\n","      output_target_seg_seg = output_target_seg_seg.detach()\n","\n","      #computing the loss of the adv net from source\n","      with amp.autocast():\n","        output_source_adv = modelADV(F.softmax(output_source_seg_seg))\n","        loss_D_source = loss_D(output_source_adv,Variable(torch.FloatTensor(output_source_adv.data.size()).fill_(source_label)).cuda())\n","        loss_D_source = loss_D_source/2\n","\n","\n","      #computing the loss of the adv net from target\n","      with amp.autocast():\n","        output_target_adv = modelADV(F.softmax(output_target_seg_seg))\n","        loss_D_target = loss_D(output_target_adv,Variable(torch.FloatTensor(output_target_adv.data.size()).fill_(target_label)).cuda())\n","        loss_D_target = loss_D_target/2\n","\n","        #Backpropagating the loss\n","    \n","        scaler.scale(loss_D_target + loss_D_source).backward()\n","      \n","\n","\n","      #Make the itearation with the optmizer\n","      scaler.step(optimizerADV)\n","      scaler.step(optimizerSEG)\n","      scaler.update()\n","\n","      tq.update(args.batch_size)\n","\n","    epoch += 1\n","\n","    \n","    #Saving Checkpoint\n","    if (epoch % args.checkpoint_step) == 0:\n","\n","      combination_parameters1 = args.context_path_model + \"_\" + \"ConvType==\" + args.ConvType +  \"_\" + args.loss_type + \"_\" +\\\n","      \"Epochs==\" + str(args.num_epochs) + \"_\" + \\\n","      \"UseLossWeights==\" + str(args.weights_loss) + \"_\" +\\\n","      \"LRSEG==\" + str(args.learning_rate) + \"_\" + \"LRADV==\" + str(args.learning_rate_adversarial) + \"_\" +\\\n","      \"LambdaADV==\" + str(args.lambda_adv_target) + \"_\" + \"BatchSize==\" + str(args.batch_size) \n","\n","\n","      EPOCH = epoch\n","      PATH_SEG = args.checkpoint_directory + \"/SEG/\" + combination_parameters1 + \"_\" + \"modelSEG.pt\"\n","      PATH_ADV = args.checkpoint_directory + \"/ADV/\" + combination_parameters1 + \"_\" + \"modelADV.pt\"\n","      \n","      \n","\n","      torch.save({\n","          'epoch': EPOCH,\n","          'model_state_dict': modelSEG.state_dict(),\n","          'optimizer_state_dict': optmizer_segmentation.state_dict(),\n","          'LRSeg': args.learning_rate,\n","          }, PATH_SEG)\n","      \n","      torch.save({\n","          'epoch': EPOCH,\n","          'model_state_dict': modelADV.state_dict(),\n","          'optimizer_state_dict': optmizer_adversarial.state_dict(),\n","          'LRAdv': args.learning_rate,\n","          'LambdaADVTarget': args.lambda_adv_target\n","          }, PATH_ADV)\n","\n","\n","\n"]},{"cell_type":"code","execution_count":13,"metadata":{"id":"-anmZKrUalkb","executionInfo":{"status":"ok","timestamp":1657645404492,"user_tz":-120,"elapsed":215,"user":{"displayName":"Marco Tommasini","userId":"11815747515139464141"}}},"outputs":[],"source":["def main(params):\n","  #Use it to compute the total execution time\n","  import time\n","  start = time.time()\n","\n","  #Setting all the standard values for the arguments\n","  parser = argparse.ArgumentParser()\n","\n","  parser.add_argument('--cityscapes_dir', type=str,\n","                      default=(directory + \"/dataset/Cityscapes\"), \n","                      help='Directory of the cityscapes dataset')\n","  parser.add_argument('--gta5_dir', type=str,\n","                      default=(directory+\"/dataset/GTA5\"), \n","                      help='Directory of the GTA5 dataset')\n","  \n","  parser.add_argument('--image_dimensions', type=tuple,\n","                        default=(512,1024), \n","                        help='Dimensions of images')\n","\n","  parser.add_argument('--num_epochs', type=int, default=50  , help='Number of epochs to train for')\n","  parser.add_argument('--analysisMode', type=str, default=\"False\"  , help='activate or not analysis mode')\n","  parser.add_argument('--checkpoint_directory', type=str, default = (directory + \"/checkpoints\") , help='Directory of the checkpoints folder')\n","  parser.add_argument('--val_results_directory', type=str, default = (directory + \"/Validations\") , help='Directory of the Validations folder')\n","  parser.add_argument('--checkpoint_step', type=int, default=1, help='How often to save checkpoints (epochs)')\n","  parser.add_argument('--number_steps', type=int, default=175, help='')\n","  parser.add_argument('--weights_loss', type=str, default=\"True\", help='Use or not the weights')\n","  parser.add_argument('--weights_loss_dir', type=str, default= directory + \"/save loss weights\", help='Directory to save loss weigths')\n","  parser.add_argument('--loss_type', type=str, default=\"CrossEntropy\", help='Choose type of loss')\n","  parser.add_argument('--ConvType', type=str, default=\"NSEP\", help='Choose type of Convolution')\n","\n","  \n","  parser.add_argument('--batch_size', type=int, default=8, help='Number of images in each batch')\n","  parser.add_argument('--context_path_model', type=str, default=\"resnet101\",\n","                      help='The context path model you are using, resnet18, resnet101.')\n","  parser.add_argument('--learning_rate', type=float, default=0.00025, help='learning rate used for train')\n","  parser.add_argument('--learning_rate_adversarial', type=float, default=0.00025, help='learning rate used for train de adersarial network')\n","  parser.add_argument(\"--lambda_adv_target\", type=float, default=0.001, help=\"lambda_adv for adversarial training.\")\n","  parser.add_argument('--data', type=str, default='', help='path of training data')\n","  parser.add_argument('--num_workers', type=int, default=4, help='num of workers')\n","  parser.add_argument('--num_classes', type=int, default=19, help='num of object classes (with void)')\n","  parser.add_argument('--cuda', type=str, default='0', help='GPU ids used for training')\n","  parser.add_argument('--use_gpu', type=bool, default=True, help='whether to user gpu for training')\n","  parser.add_argument('--pretrained_model_path', type=str, default=None, help='path to pretrained model')\n","  parser.add_argument('--save_model_path', type=str, default=None, help='path to save model')\n","\n","  args = parser.parse_args(params)\n","\n","  #loading data\n","  dataset_target = CityScapeDataSet(args.cityscapes_dir, os.path.join(args.cityscapes_dir, \"images\"), \"train.txt\", target_dimensions = args.image_dimensions)\n","  dataset_source = GTA5DataSet(args.gta5_dir, os.path.join(args.gta5_dir, \"images\"), os.path.join(args.gta5_dir, \"labels\"), \"train.txt\", image_dimensions = args.image_dimensions)\n","  dataset_val = CityScapeDataSet_val(args.cityscapes_dir, os.path.join(args.cityscapes_dir, \"images\"), os.path.join(args.cityscapes_dir, \"labels\"), \"val.txt\", image_dimensions = args.image_dimensions)\n","  print(len(dataset_target))\n","\n","  dataloader_target = DataLoader(dataset_target, batch_size = args.batch_size, num_workers = args.num_workers, shuffle = True, drop_last= True, persistent_workers= True)\n","  dataloader_source = DataLoader(dataset_source, batch_size = args.batch_size, num_workers = args.num_workers, shuffle = True, drop_last= True, persistent_workers= True)\n","  dataloader_val = DataLoader(dataset_val, batch_size = 1, num_workers = args.num_workers, shuffle = True, drop_last= False)\n","\n","\n","  #initialize models\n","  os.environ['CUDA_VISIBLE_DEVICES'] = args.cuda\n","\n","  #Setting the combination of parameters that will be used as the name to the saved checkpoints\n","  combination_parameters2 = args.context_path_model + \"_\" + \"ConvType==\" + args.ConvType +  \"_\" + args.loss_type + \"_\" +\\\n","  \"Epochs==\" + str(args.num_epochs) + \"_\" + \\\n","  \"UseLossWeights==\" + str(args.weights_loss) + \"_\" +\\\n","  \"LRSEG==\" + str(args.learning_rate) + \"_\" + \"LRADV==\" + str(args.learning_rate_adversarial) + \"_\" +\\\n","  \"LambdaADV==\" + str(args.lambda_adv_target) + \"_\" + \"BatchSize==\" + str(args.batch_size)\n","\n","  print(\"combParam2 = \",combination_parameters2)\n","\n","  #Defining if the discriminator will be composed of Separable convolutions or standard convolutions\n","  modelSEG = BiSeNet(args.num_classes, args.context_path_model)\n","  if args.ConvType == \"NSEP\":\n","    modelADV = Discriminator(args.num_classes)\n","  elif args.ConvType == \"SEP\":\n","    modelADV = DiscriminatorSEP(args.num_classes)\n","\n","  \n","  if torch.cuda.is_available() and args.use_gpu and args.analysisMode == \"False\":\n","      modelSEG = torch.nn.DataParallel(modelSEG).cuda()\n","      modelADV = torch.nn.DataParallel(modelADV).cuda()\n","  \n","  #Here we have to to define the optmizers\n","  optmizer_segmentation = torch.optim.SGD(modelSEG.parameters(), args.learning_rate, momentum=0.9, weight_decay=1e-4)\n","  optmizer_adversarial = torch.optim.Adam(modelADV.parameters(), lr=args.learning_rate_adversarial, betas=(0.9, 0.99))\n","\n","  #Find out the parameters of the models\n","  #Analysis mode is the parameters that decides if the program will either run normally or just compute the metrics of the model\n","  if args.analysisMode == \"True\":\n","    import sys\n","    number_parametersSEG = sum(param.numel() for param in modelSEG.parameters())\n","    number_parametersADV = sum(param.numel() for param in modelADV.parameters())\n","    print(\"Num Param SEG: \", number_parametersSEG)\n","    print(\"Num Param ADV: \", number_parametersADV)\n","    \n","    label = torch.randn((1, 19, 1024, 512))\n","    macs, _ = profile(modelADV, inputs=(label, ))\n","    print(\"Floating point operations for Adversarial network is approximately: \",2*macs )\n","    print(\"Name: \", args.context_path_model + \"_\" + \"ConvType==\" + args.ConvType)\n","    sys.exit()\n","\n","\n","\n","  #Import checkpoints \n","  #If you define false it will just overwrite the current checkpoints or create new checkpoints\n","  use_checkpoints = False\n","  if use_checkpoints:\n","    checkpoint_seg = torch.load(args.checkpoint_directory + \"/SEG/\" + combination_parameters2 + \"_\" + \"modelSEG.pt\")\n","    checkpoint_adv = torch.load(args.checkpoint_directory + \"/ADV/\" + combination_parameters2 + \"_\" + \"modelADV.pt\")\n","  else:\n","    checkpoint_seg = None\n","    checkpoint_adv = None\n","\n","  #Doing the calculation for the number of iterations\n","  size_iterations = len(dataloader_source.dataset)/args.batch_size\n","  params_update = ['--number_steps', str(int(size_iterations))]\n","  params = params + params_update\n","  args = parser.parse_args(params)\n","\n","  #Calling the training function\n","  train_model(args, modelSEG, modelADV, optmizer_segmentation, optmizer_adversarial, dataloader_target, dataloader_source,checkpoint_seg, checkpoint_adv)\n","  #Calling the validation function\n","  precision, MIOU = validation_segmentation(args, modelSEG, dataloader_val, combination_parameters2)\n","\n","  end = time.time()\n","  elapsed = end - start\n","  print(\"Elapsed Time :\", elapsed, \" Seconds\")\n","  #Print the total elapsed time and finish the program\n","  \n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"WZkE6YBkD8L9"},"outputs":[],"source":["if __name__ == '__main__':\n","  #This section was used for testing with different parameters\n","  #You can use these lists to train the model with multiple configurations without having to restart the program\n","  #Saves already all the validation results and all the checkpoints\n","  list_networks = list([\"resnet101\"])\n","  list_useWeights = list([\"False\"])\n","  list_convType = list([\"NSEP\"])\n","  epochs_size = list([\"100\"])\n","  list_losses = list([\"CrossEntropy\"])\n","\n","  for model in list_networks:\n","    for use in list_useWeights:\n","      for typeC in list_convType:\n","        for ep in epochs_size:\n","          for loss in list_losses:\n","            #Empties the GPU memory and sets the arguments\n","            torch.cuda.empty_cache()\n","            if model == \"resnet101\":\n","              params = [\"--context_path_model\", model,\n","                        \"--weights_loss\", use,\n","                        \"--batch_size\", '4', #With more than 4 the GPU runs out of memory\n","                        \"--ConvType\", typeC,\n","                        \"--num_epochs\", ep,\n","                        '--loss_type',loss,\n","                        '--analysisMode', 'False',]\n","            else:\n","              params = [\"--context_path_model\", model,\n","                        \"--weights_loss\", use,\n","                        \"--batch_size\", '8',\n","                        \"--ConvType\", typeC,\n","                        \"--num_epochs\", ep,\n","                        '--loss_type',loss,\n","                        '--analysisMode', 'False',]\n","           \n","            main(params)\n","            "]},{"cell_type":"code","source":[""],"metadata":{"id":"D3reCsXn-vQ1","executionInfo":{"status":"aborted","timestamp":1657645425296,"user_tz":-120,"elapsed":9,"user":{"displayName":"Marco Tommasini","userId":"11815747515139464141"}}},"execution_count":null,"outputs":[]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":[],"name":"training.ipynb","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}