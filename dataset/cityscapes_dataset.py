# -*- coding: utf-8 -*-
"""cityscapes_dataset.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1jRiwqqH15MC3IlflEBxAMdFvoCkjUEwq
"""

import os
import torch
from torchvision.io import read_image
from torch.utils import data
from torchvision.transforms.functional import convert_image_dtype
import cv2
import numpy as np
from torch.utils.data import Dataset
from torch.utils.data import DataLoader
from PIL import Image

class CityScapeDataSet(data.Dataset):
  def __init__(self, dataset_directory = None, target_directory = None, name_list = None, target_dimensions = (1024, 512)):
    self.name_list = name_list
    self.dataset_directory = dataset_directory
    self.file_name_list =  [file_name.strip() for file_name in open(os.path.join(dataset_directory, name_list))]
    self.target_directory = target_directory
    self.target_dimensions = target_dimensions
    


  def __len__(self):
    return len(self.file_name_list)

  def __getitem__(self, position):
    target_path = os.path.join(self.target_directory, self.file_name_list[position])

    #here we read the image and convert it to RGB from BGR
    target_RGB = np.asarray(Image.open(target_path).convert("RGB").resize(self.target_dimensions,  Image.BICUBIC), np.float32)
    

    size = target_RGB.shape
    target_RGB = target_RGB[:, :, ::-1]  # change to BGR
    IMG_MEAN = np.array((104.00698793, 116.66876762, 122.67891434), dtype=np.float32)
    target_RGB -= IMG_MEAN 
    imagtarget_RGBe_RGB = target_RGB.transpose((2, 0, 1))


    return imagtarget_RGBe_RGB.copy()