{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"cityscapes_dataset.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"N39X_u-igqF-"},"outputs":[],"source":["import os\n","import torch\n","from torchvision.io import read_image\n","from torch.utils import data\n","from torchvision.transforms.functional import convert_image_dtype\n","import cv2\n","import numpy as np\n","from torch.utils.data import Dataset\n","from torch.utils.data import DataLoader\n","from PIL import Image"]},{"cell_type":"code","source":["class CityScapeDataSet(data.Dataset):\n","  def __init__(self, dataset_directory = None, target_directory = None, name_list = None, target_dimensions = (1024, 512)):\n","    self.name_list = name_list\n","    self.dataset_directory = dataset_directory\n","    self.file_name_list =  [file_name.strip() for file_name in open(os.path.join(dataset_directory, name_list))]\n","    self.target_directory = target_directory\n","    self.target_dimensions = target_dimensions\n","    \n","\n","\n","  def __len__(self):\n","    return len(self.file_name_list)\n","\n","  def __getitem__(self, position):\n","    target_path = os.path.join(self.target_directory, self.file_name_list[position])\n","\n","    #here we read the image and convert it to RGB from BGR\n","    target_RGB = np.asarray(Image.open(target_path).convert(\"RGB\").resize(self.target_dimensions,  Image.BICUBIC), np.float32)\n","    \n","\n","    size = target_RGB.shape\n","    target_RGB = target_RGB[:, :, ::-1]  # change to BGR\n","    target_RGB = target_RGB/255 \n","    imagtarget_RGBe_RGB = target_RGB.transpose((2, 0, 1))\n","\n","\n","    return imagtarget_RGBe_RGB.copy()"],"metadata":{"id":"D6Q88Pj3Uo8Q"},"execution_count":null,"outputs":[]}]}