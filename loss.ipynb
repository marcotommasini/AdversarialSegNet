{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"loss.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"id":"SN574AV6TjWo","executionInfo":{"status":"ok","timestamp":1655812583363,"user_tz":-120,"elapsed":4069,"user":{"displayName":"Marco Tommasini","userId":"11815747515139464141"}}},"outputs":[],"source":["import torch.nn as nn\n","import torch\n","import torch.nn.functional as F\n","from torch.autograd import Variable\n","import os"]},{"cell_type":"code","source":["def flatten(tensor):\n","    \"\"\"Flattens a given tensor such that the channel axis is first.\n","    The shapes are transformed as follows:\n","       (N, C, D, H, W) -> (C, N * D * H * W)\n","    \"\"\"\n","    C = tensor.size(1)\n","    # new axis order\n","    axis_order = (1, 0) + tuple(range(2, tensor.dim()))\n","    # Transpose: (N, C, D, H, W) -> (C, N, D, H, W)\n","    transposed = tensor.permute(axis_order)\n","    # Flatten: (C, N, D, H, W) -> (C, N * D * H * W)\n","    return transposed.contiguous().view(C, -1)"],"metadata":{"id":"J7vEKkdETpht"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class DiceLoss(nn.Module):\n","    def __init__(self):\n","        super().__init__()\n","        self.epsilon = 1e-5\n","\n","    def forward(self, output, target):\n","        assert output.size() == target.size(), \"'input' and 'target' must have the same shape\"\n","        output = F.softmax(output, dim=1)\n","        output = flatten(output)\n","        target = flatten(target)\n","        # intersect = (output * target).sum(-1).sum() + self.epsilon\n","        # denominator = ((output + target).sum(-1)).sum() + self.epsilon\n","\n","        intersect = (output * target).sum(-1)\n","        denominator = (output + target).sum(-1)\n","        dice = intersect / denominator\n","        dice = torch.mean(dice)\n","        return 1 - dice\n","        # return 1 - 2. * intersect / denominator"],"metadata":{"id":"XkDHMrvxTrOR"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class CrossEntropyLoss(nn.Module):\n","  def __init__(self, background_label_value = 255):\n","    super().__init__()\n","    self.background = background_label_value\n","  \n","  def forward(self, prediction, target, weight = None):\n","    \n","    batch_size, number_classes, height, width = prediction.size()\n","    target_mask = (target >= 0) * (target != self.background)\n","    target = target[target_mask]\n","\n","    if not target.data.dim():\n","      return Variable(torch.zeros(1))\n","\n","    prediction = prediction.transpose(1, 2).transpose(2, 3).contiguous()\n","    prediction = prediction[target_mask.view(batch_size, height, width, 1).repeat(1, 1, 1, number_classes)].view(-1, number_classes)\n","\n","    loss = F.cross_entropy(prediction, target, weight=weight)\n","    return loss\n","    \n"],"metadata":{"id":"0pTyJB5BT7Gz"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def find_frequency_class(data_loader):\n","  density_categories = {}\n","  for _, label in data_loader:\n","    array_pixels = label.flatten().numpy()\n","    categories_contained = np.unique(array_pixels)\n","\n","    for category in categories_contained:\n","      if str(catergory) in density_categories.keys():\n","        density_category[str(category)] += 1\n","      else:\n","        density_category[str(category)] = 1\n","  return density_categories\n","\n","\n"],"metadata":{"id":"qaKVAKWRWAjB"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class FocalLoss(nn.Module):\n","  \"\"\"Implementation of Facal Loss\"\"\"\n","  def __init__(self, weight=None, gamma=2, reduction=\"mean\", ignore_index=255):\n","      super(FocalLoss, self).__init__()\n","      self.weighted_cs = nn.CrossEntropyLoss(weight=weight, reduction=\"none\", ignore_index=ignore_index)\n","      self.cs = nn.CrossEntropyLoss(reduction=\"none\", ignore_index=ignore_index)\n","      self.gamma = gamma\n","      self.reduction = reduction\n","      \n","  def forward(self, predicted, target):\n","      \"\"\"\n","      predicted: [batch_size, n_classes]\n","      target: [batch_size]\n","      \"\"\"\n","      pt = 1/torch.exp(self.cs(predicted,target))\n","      #shape: [batch_size]\n","      entropy_loss = self.weighted_cs(predicted, target)\n","      #shape: [batch_size]\n","      focal_loss = ((1-pt)**self.gamma)*entropy_loss\n","      #shape: [batch_size]\n","      if self.reduction ==\"none\":\n","          return focal_loss\n","      elif self.reduction == \"mean\":\n","          return focal_loss.mean()\n","      else:\n","          return focal_loss.sum()"],"metadata":{"id":"9I2fpgLSjrTV"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["############## COMPUTE WEIGHTS #####################\n","# Compute weights for each classes of the dataset  #\n","# Receive in input:                                #             \n","# savedir: the directory where to save the weights #\n","# dataloader: the train dataloader                 #\n","# num_classes: the number of total classes         #                      \n","####################################################\n","def calculate_weigths_labels(savedir, dataloader, num_classes):\n","    # Create an instance from the data loader\n","    z = np.zeros((num_classes,))\n","    # Initialize tqdm\n","    print('Calculating classes weights')\n","    for step, (images, labels) in enumerate(dataloader):\n","        x = images\n","        y = labels.detach().cpu().numpy()\n","        mask = (y >= 0) & (y < num_classes)\n","        labels = y[mask].astype(np.uint8)\n","        count_l = np.bincount(labels, minlength=num_classes)\n","        z += count_l\n","\n","\n","    total_frequency = np.sum(z)\n","    class_weights = []\n","    for frequency in z:\n","        class_weight = 1 / (np.log(1.02 + (frequency / total_frequency)))\n","        class_weights.append(float(class_weight))\n","    ret = np.array(class_weights)\n","    classes_weights_path = os.path.join(savedir, 'classes_weights.npy')\n","    np.save(classes_weights_path, ret)\n","    \n","    ret = torch.from_numpy(ret).type(torch.FloatTensor)\n","    return ret"],"metadata":{"id":"IYANZCZ4B-n0"},"execution_count":null,"outputs":[]}]}